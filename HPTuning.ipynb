{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HPTuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOVgZi3cJkHRxBgsqyUshyq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashlal/Deepfake-Microbiomes/blob/main/HPTuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qB4bbEIUhSTA"
      },
      "source": [
        "from newsolver import predict_community_fullnp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "from numba import njit\n",
        "from numba.typed import List\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import pickle\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "import logging\n",
        "import tqdm\n",
        "\n",
        "logging.basicConfig(filename='output.log', level=logging.DEBUG)\n",
        "\n",
        "data = pd.read_excel('RealData.xlsx', index_col=0)\n",
        "specs = data.columns.tolist()\n",
        "trimmed_specs = []\n",
        "\n",
        "for i in range(len(specs)):\n",
        "    if data.iloc[:,i].astype(bool).sum() >= 85:\n",
        "        trimmed_specs.append(specs[i])\n",
        "dim1 = len(trimmed_specs)\n",
        "\n",
        "typed_trimmed_specs = List()\n",
        "[typed_trimmed_specs.append(x) for x in trimmed_specs]\n",
        "\n",
        "@njit()\n",
        "def get_LT(full_ar):\n",
        "    ar = []\n",
        "    for i in range(len(full_ar)):\n",
        "        for j in range(i):\n",
        "            ar.append(full_ar[i][j])\n",
        "    return ar\n",
        "\n",
        "@njit()\n",
        "def generate_matrix(comm, tolerance):\n",
        "    dim = len(comm)\n",
        "    ar = np.zeros((dim,dim))\n",
        "\n",
        "    for i in range(dim):\n",
        "        for j in range(i+1):\n",
        "            if i == j:\n",
        "                ar[i][j] = 0\n",
        "            else:\n",
        "                r = rd.random()\n",
        "                # m = mult[i*dim1+j]\n",
        "                ar[i][j] = r\n",
        "                ar[j][i] = (1-r)\n",
        "\n",
        "    return ar\n",
        "\n",
        "def datagen():\n",
        "    lm = generate_matrix(typed_trimmed_specs, 0)\n",
        "    cm = predict_community_fullnp(lm, trimmed_specs, verb=False)\n",
        "    return (cm, get_LT(lm))\n",
        "\n",
        "# select CUDA if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if str(device) == 'cuda:0':\n",
        "\tprint('CUDA device selected!')\n",
        "elif str(device) == 'cpu':\n",
        "\tprint('CUDA device not available. CPU selected')\n",
        "\n",
        "# hyperparam = 470\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self, hyperparam):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(462, hyperparam)\n",
        "        self.fc2 = nn.Linear(hyperparam, 231*461)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "mytest_x = []\n",
        "mytest_y = []\n",
        "\n",
        "for i in range(50):\n",
        "      x, y = datagen()\n",
        "      mytest_x.append(torch.from_numpy(x).float().to(device))\n",
        "      mytest_y.append(torch.FloatTensor(y).to(device))\n",
        "\n",
        "def test_net(model, test_x, test_y):\n",
        "    test_loss = 0\n",
        "    for i in range(len(test_x)):\n",
        "      input, true_y = test_x[i], test_y[i]\n",
        "\n",
        "      output = model(input).to(device)\n",
        "      loss = criterion(output, true_y).to(device)\n",
        "      test_loss += sqrt((loss.item())/(231*461))\n",
        "\n",
        "    return test_loss/(len(test_x))\n",
        "\n",
        "def testconfig(model):\n",
        "  s_arr = []\n",
        "  for i in range(3000):\n",
        "      optimizer.zero_grad()\n",
        "      x, y = datagen()\n",
        "      input = torch.from_numpy(x).float().to(device)\n",
        "      true_y = torch.FloatTensor(y).to(device)\n",
        "\n",
        "      output = model(input).to(device)\n",
        "\n",
        "      loss = criterion(output, true_y).to(device)\n",
        "      s = sqrt((loss.item())/(231*461))\n",
        "      s_arr.append(s)\n",
        "      print(f'Epoch {i}: {s}')\n",
        "      loss.backward()\n",
        "\n",
        "      optimizer.step()\n",
        "  acc = test_net(model, mytest_x, mytest_y)\n",
        "  return acc\n",
        "\n",
        "for it in range(470, 4630, 10):\n",
        "  hyperparam = it\n",
        "  net = MyNet(hyperparam).to(device)\n",
        "  criterion = nn.MSELoss(reduction='sum')\n",
        "  optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "\n",
        "  acc = testconfig(net)\n",
        "  logging.info(f'Hidden Layer n={it}')\n",
        "  logging.info(f'Test Acc: {acc}')\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}