{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashlal/Deepfake-Microbiomes/blob/main/Multiset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBjl1GZXA0W5"
      },
      "source": [
        "from newsolver import predict_community_fullnp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "from numba import njit\n",
        "from numba.typed import List\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from modules import *\n",
        "from scipy.stats import wasserstein_distance as WD\n",
        "\n",
        "data = pd.read_excel('RealData.xlsx', index_col=0)\n",
        "specs = data.columns.tolist()\n",
        "trimmed_specs = []\n",
        "typed_trimmed_specs = List()\n",
        "\n",
        "for i in range(len(specs)):\n",
        "    if data.iloc[:,i].astype(bool).sum() >= 85:\n",
        "        trimmed_specs.append(specs[i])\n",
        "        typed_trimmed_specs.append(specs[i])\n",
        "\n",
        "# select CUDA if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if str(device) == 'cuda:0':\n",
        "    print('CUDA device selected!')\n",
        "elif str(device) == 'cpu':\n",
        "\tprint('CUDA device not available. CPU selected')\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self, hyperparam):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(462, hyperparam)\n",
        "        self.fc2 = nn.Linear(hyperparam, 231*461)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_net(model, train_size, super_train_size):\n",
        "    loss_values = []\n",
        "    pbar2=tqdm(range(super_train_size))\n",
        "    pbar2.set_description(f'Training Neural Net on {super_train_size} SuperEpochs')\n",
        "    for super_epoch in range(super_train_size):\n",
        "      full_m = pd.DataFrame(generate_matrix(typed_trimmed_specs), index=trimmed_specs, columns=trimmed_specs)\n",
        "      train_y = get_LT(full_m.to_numpy())\n",
        "\n",
        "      for epoch in pbar2:\n",
        "\n",
        "          npcm = np.zeros(len(trimmed_specs))\n",
        "          size = rd.randint(25, 235)\n",
        "          subset = rd.sample(trimmed_specs, size)\n",
        "          subset_lam = (full_m.loc[subset, subset]).to_numpy()\n",
        "          cm = predict_community_fullnp(subset_lam, subset, verb=False)\n",
        "\n",
        "          for i in range(len(cm)):\n",
        "              npcm[trimmed_specs.index(subset[i])] = cm[i]\n",
        "\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          x, y = npcm, train_y\n",
        "\n",
        "          input = torch.from_numpy(x).float().to(device)\n",
        "          true_y = torch.FloatTensor(y).to(device)\n",
        "          output = model(input).to(device)\n",
        "          loss = criterion(output, true_y).to(device)\n",
        "          s = sqrt(loss.item()/(231*461))\n",
        "          if (epoch % 10)==0:\n",
        "            print(f'SuperEpoch {super_epoch}: Epoch {epoch}: Loss {s}')\n",
        "          loss_values.append(s)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          if s<=0.002:\n",
        "            break\n",
        "\n",
        "    return loss_values\n",
        "\n",
        "if __name__=='__main__':\n",
        "    super_train_size, train_size, test_size, param, = 300, 3000, 25, 2500\n",
        "    path = 'model.pth'\n",
        "\n",
        "    net = MyNet(param).to(device)\n",
        "\n",
        "    #Multi GPU Support\n",
        "    if torch.cuda.device_count() > 1:\n",
        "          print(f'Using {torch.cuda.device_count()} GPUs')\n",
        "          net = nn.DataParallel(net)\n",
        "    elif torch.cuda.device_count() == 1:\n",
        "        print(f'Using {torch.cuda.device_count()} GPU')\n",
        "\n",
        "    criterion = nn.MSELoss(reduction='sum')\n",
        "    optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "\n",
        "    lv = train_net(net, train_size=train_size, super_train_size=super_train_size)\n",
        "\n",
        "    plt.plot(lv)\n",
        "    plt.savefig('Loss')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}