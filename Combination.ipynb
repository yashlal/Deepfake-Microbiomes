{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Combination.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashlal/Deepfake-Microbiomes/blob/main/Combination.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCwNKSCNfQDJ"
      },
      "source": [
        "from newsolver import predict_community_fullnp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "from numba import njit\n",
        "from numba.typed import List\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import pickle\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from modules import regenerate_PWMatrix\n",
        "from scipy.stats import wasserstein_distance as WD\n",
        "\n",
        "train_size, test_size = 5000, 25\n",
        "\n",
        "data = pd.read_excel('RealData.xlsx', index_col=0)\n",
        "specs = data.columns.tolist()\n",
        "trimmed_specs = []\n",
        "\n",
        "for i in range(len(specs)):\n",
        "    if data.iloc[:,i].astype(bool).sum() >= 85:\n",
        "        trimmed_specs.append(specs[i])\n",
        "dim1 = len(trimmed_specs)\n",
        "\n",
        "typed_trimmed_specs = List()\n",
        "[typed_trimmed_specs.append(x) for x in trimmed_specs]\n",
        "\n",
        "@njit()\n",
        "def get_LT(full_ar):\n",
        "    ar = []\n",
        "    for i in range(len(full_ar)):\n",
        "        for j in range(i):\n",
        "            ar.append(full_ar[i][j])\n",
        "    return ar\n",
        "\n",
        "@njit()\n",
        "def generate_matrix(comm, tolerance):\n",
        "    dim = len(comm)\n",
        "    ar = np.zeros((dim,dim))\n",
        "\n",
        "    for i in range(dim):\n",
        "        for j in range(i+1):\n",
        "            if i == j:\n",
        "                ar[i][j] = 0\n",
        "            else:\n",
        "                r = rd.random()\n",
        "                # m = mult[i*dim1+j]\n",
        "                ar[i][j] = r\n",
        "                ar[j][i] = (1-r)\n",
        "\n",
        "    return ar\n",
        "\n",
        "def datagen():\n",
        "    lm = generate_matrix(typed_trimmed_specs, 0)\n",
        "    cm = predict_community_fullnp(lm, trimmed_specs, verb=False)\n",
        "    return (cm, get_LT(lm))\n",
        "\n",
        "# select CUDA if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if str(device) == 'cuda:0':\n",
        "    print('CUDA device selected!')\n",
        "elif str(device) == 'cpu':\n",
        "\tprint('CUDA device not available. CPU selected')\n",
        "\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self, hyperparam):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(462, hyperparam)\n",
        "        self.fc2 = nn.Linear(hyperparam, 231*461)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "mytest_x = []\n",
        "mytest_y = []\n",
        "mytrain_x = []\n",
        "mytrain_y = []\n",
        "\n",
        "pbar1=tqdm(range(test_size))\n",
        "pbar1.set_description('Generating Test Set')\n",
        "for i in pbar1:\n",
        "    x, y = datagen()\n",
        "    mytest_x.append(torch.from_numpy(x).float().to(device))\n",
        "    mytest_y.append(torch.FloatTensor(y).to(device))\n",
        "\n",
        "pbar2=tqdm(range(train_size))\n",
        "pbar2.set_description('Generating Train Set')\n",
        "for i in pbar2:\n",
        "    x, y = datagen()\n",
        "    mytrain_x.append(torch.from_numpy(x).float().to(device))\n",
        "    mytrain_y.append(torch.FloatTensor(y).to(device))\n",
        "\n",
        "def test_net_comm(model, test_x):\n",
        "    for i in range(test_size):\n",
        "        cm_real = test_x[i]\n",
        "        output = model(input).to(device).tolist()\n",
        "        mat_y = np.array(regenerate_PWMatrix(output))\n",
        "        cm_pred = predict_community_fullnp(mat_y, trimmed_specs)\n",
        "        print(f'Test {i}: WD Distance {WD(cm_pred, cm_real)}')\n",
        "\n",
        "def train_net(model, train_x, train_y):\n",
        "    pbar3=tqdm(range(train_size))\n",
        "    pbar3.set_description('Training Neural Net')\n",
        "    for i in pbar3:\n",
        "        optimizer.zero_grad()\n",
        "        input, true_y = train_x[i], train_y[i]\n",
        "        output = model(input).to(device)\n",
        "        loss = criterion(output, true_y).to(device)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "def main(param1):\n",
        "    net = MyNet(param1).to(device)\n",
        "\n",
        "    #Multi GPU Support\n",
        "    if torch.cuda.device_count() > 1:\n",
        "          print(f'Using {torch.cuda.device_count()} GPUs')\n",
        "          net = nn.DataParallel(net)\n",
        "    elif torch.cuda.device_count() == 1:\n",
        "        print(f'Using {torch.cuda.device_count()} GPU')\n",
        "    criterion = nn.MSELoss(reduction='sum')\n",
        "    optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "    train_net(net, mytrain_x, mytrain_y)\n",
        "    test_net_comm(net, mytest_x)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}