{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NetGPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNZ8OIPf+s0HqvQntx9nE+3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4ac7c05b38b4477985e840564d0583b1": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "state": {
            "_view_name": "OutputView",
            "msg_id": "",
            "_dom_classes": [],
            "_model_name": "OutputModel",
            "outputs": [
              {
                "output_type": "display_data",
                "metadata": {
                  "tags": []
                },
                "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">⠸</span> Training...\n</pre>\n",
                "text/plain": "\u001b[32m⠸\u001b[0m Training...\n"
              }
            ],
            "_view_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_view_count": null,
            "_view_module_version": "1.0.0",
            "layout": "IPY_MODEL_aca6b093f2e846dfbe508ea44c074de2",
            "_model_module": "@jupyter-widgets/output"
          }
        },
        "aca6b093f2e846dfbe508ea44c074de2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashlal/Deepfake-Microbiomes/blob/main/NetGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4ac7c05b38b4477985e840564d0583b1",
            "aca6b093f2e846dfbe508ea44c074de2"
          ]
        },
        "id": "8_Be9_icVmNu",
        "outputId": "e4a574a0-5bd2-459e-c9bd-d791ca2fafb4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from math import sqrt\n",
        "\n",
        "# select CUDA if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if str(device) == 'cuda:0':\n",
        "\tprint('CUDA device selected!')\n",
        "elif str(device) == 'cpu':\n",
        "\tprint('CUDA device not available. CPU selected')\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(462, 462*5)\n",
        "        self.fc2 = nn.Linear(462*5, 462*5)\n",
        "        self.fc3 = nn.Linear(462*10, 462*10)\n",
        "        self.fc4 = nn.Linear(462*10, 231*461)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "       \tx = F.relu(self.fc3(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "\n",
        "net = MyNet().to(device)\n",
        "criterion = nn.MSELoss(reduction='mean')\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "\n",
        "for n in range(1,8):\n",
        "    d_PATH = f'drive/MyDrive/YashData/{n}'\n",
        "    f = open(d_PATH, 'rb')\n",
        "    data = pickle.load(f)\n",
        "\n",
        "    for i in range(1000):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        input = torch.from_numpy(data[i][1]).float().to(device)\n",
        "        true_y = torch.FloatTensor(data[i][0]).to(device)\n",
        "\n",
        "        output = net(input).to(device)\n",
        "\n",
        "        loss = criterion(output, true_y).to(device)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        print(f'Epoch {i}: {sqrt(loss.item())}')\n",
        "\n",
        "PATH = 'model.pth'\n",
        "torch.save(net.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA device selected!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ac7c05b38b4477985e840564d0583b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Output()"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: 0.5769283953140336\n",
            "Epoch 1: 0.5784328517387007\n",
            "Epoch 2: 0.5760460409052383\n",
            "Epoch 3: 0.5737825930028958\n",
            "Epoch 4: 0.5725837057879799\n",
            "Epoch 5: 0.571478683432908\n",
            "Epoch 6: 0.5679790102361194\n",
            "Epoch 8: 0.5601631472706957\n",
            "Epoch 9: 0.5557072627700402\n",
            "Epoch 10: 0.5497337824089097\n",
            "Epoch 11: 0.5420835400824576\n",
            "Epoch 12: 0.5345351798931441\n",
            "Epoch 13: 0.5238961160728074\n",
            "Epoch 14: 0.509817683459306\n",
            "Epoch 15: 0.4993604056096057\n",
            "Epoch 16: 0.48215308790352457\n",
            "Epoch 17: 0.46490325867386134\n",
            "Epoch 18: 0.44408297202311\n",
            "Epoch 19: 0.4241719587173292\n",
            "Epoch 20: 0.3989602194294117\n",
            "Epoch 21: 0.38121135781616095\n",
            "Epoch 22: 0.34967965213536223\n",
            "Epoch 23: 0.3309950535720127\n",
            "Epoch 24: 0.3059337754456343\n",
            "Epoch 25: 0.30108729806429935\n",
            "Epoch 26: 0.3027173068249529\n",
            "Epoch 27: 0.31387058344050106\n",
            "Epoch 28: 0.32971604933223353\n",
            "Epoch 29: 0.32602477040045447\n",
            "Epoch 30: 0.3360949080982411\n",
            "Epoch 31: 0.33825885134715694\n",
            "Epoch 32: 0.3308389461475206\n",
            "Epoch 33: 0.3229713803771545\n",
            "Epoch 34: 0.3103103336631245\n",
            "Epoch 35: 0.3007881857332445\n",
            "Epoch 36: 0.2973374604538694\n",
            "Epoch 37: 0.2963904265874114\n",
            "Epoch 38: 0.2972769901744761\n",
            "Epoch 39: 0.29911514908988773\n",
            "Epoch 40: 0.30018929033065217\n",
            "Epoch 41: 0.3034911755861083\n",
            "Epoch 42: 0.30608895358913035\n",
            "Epoch 43: 0.3064652810237362\n",
            "Epoch 44: 0.3063163378937619\n",
            "Epoch 45: 0.3044474463047026\n",
            "Epoch 46: 0.3024075867044957\n",
            "Epoch 47: 0.3052390925538603\n",
            "Epoch 49: 0.30155713466951023\n",
            "Epoch 50: 0.3030340249901378\n",
            "Epoch 51: 0.29897960239386\n",
            "Epoch 52: 0.2973958766467346\n",
            "Epoch 53: 0.29848494177605084\n",
            "Epoch 54: 0.2982815125126031\n",
            "Epoch 55: 0.29958411188559425\n",
            "Epoch 56: 0.2995862382412822\n",
            "Epoch 58: 0.30090069566553085\n",
            "Epoch 59: 0.29995406961508403\n",
            "Epoch 60: 0.29879556116933276\n",
            "Epoch 62: 0.29665592542948216\n",
            "Epoch 63: 0.29625193565074304\n",
            "Epoch 64: 0.2961530314060583\n",
            "Epoch 65: 0.2962009784322686\n",
            "Epoch 66: 0.2958575305422899\n",
            "Epoch 67: 0.2957954227419315\n",
            "Epoch 68: 0.29582116405324704\n",
            "Epoch 69: 0.2963183856855101\n",
            "Epoch 70: 0.2956515122273835\n",
            "Epoch 71: 0.2966641505519558\n",
            "Epoch 72: 0.2951163983034681\n",
            "Epoch 73: 0.29540830249047106\n",
            "Epoch 74: 0.29572990074527933\n",
            "Epoch 75: 0.29519622875281926\n",
            "Epoch 76: 0.2957275325120415\n",
            "Epoch 77: 0.29601241582448284\n",
            "Epoch 78: 0.29563176693742393\n",
            "Epoch 79: 0.29536515831099575\n",
            "Epoch 80: 0.29585776978070616\n",
            "Epoch 82: 0.29549327343096043\n",
            "Epoch 83: 0.29543488454175476\n",
            "Epoch 84: 0.2952757222117108\n",
            "Epoch 85: 0.29702204275133615\n",
            "Epoch 86: 0.2947772347160514\n",
            "Epoch 87: 0.29582492935081817\n",
            "Epoch 88: 0.29538774641804066\n",
            "Epoch 89: 0.29515678952977076\n",
            "Epoch 90: 0.2953955150160144\n",
            "Epoch 91: 0.29605945448932697\n",
            "Epoch 92: 0.2943181053384459\n",
            "Epoch 93: 0.2944999607374363\n",
            "Epoch 94: 0.29636240927033436\n",
            "Epoch 95: 0.2948100275830031\n",
            "Epoch 96: 0.29553315935771574\n",
            "Epoch 97: 0.2946486944697905\n",
            "Epoch 98: 0.2945862685807757\n",
            "Epoch 99: 0.29538128924605744\n",
            "Epoch 100: 0.2948150188555984\n",
            "Epoch 101: 0.29549153365675634\n",
            "Epoch 102: 0.29536084480769526\n",
            "Epoch 103: 0.2948981900841312\n",
            "Epoch 104: 0.2952911894037125\n",
            "Epoch 106: 0.2955792408181186\n",
            "Epoch 107: 0.29498015074304546\n",
            "Epoch 108: 0.29558617258245296\n",
            "Epoch 109: 0.2955534406230681\n",
            "Epoch 110: 0.2953674790001591\n",
            "Epoch 111: 0.29564508601739736\n",
            "Epoch 112: 0.29495610423744967\n",
            "Epoch 113: 0.2947982377352248\n",
            "Epoch 114: 0.2951133939851412\n",
            "Epoch 115: 0.2952898269103674\n",
            "Epoch 116: 0.29473996394222096\n",
            "Epoch 117: 0.29496192660170306\n",
            "Epoch 118: 0.2947896193488282\n",
            "Epoch 119: 0.2952937882161801\n",
            "Epoch 120: 0.2955232892266625\n",
            "Epoch 121: 0.2951254236976849\n",
            "Epoch 122: 0.29548651598972225\n",
            "Epoch 123: 0.2955485500537295\n",
            "Epoch 124: 0.2955386426214221\n",
            "Epoch 125: 0.29517544336147555\n",
            "Epoch 126: 0.29408077274429956\n",
            "Epoch 127: 0.29519963605439614\n",
            "Epoch 128: 0.29455498111549244\n",
            "Epoch 129: 0.2955280037365137\n",
            "Epoch 130: 0.2959930973536888\n",
            "Epoch 131: 0.29511076833735667\n",
            "Epoch 132: 0.29520233662844825\n",
            "Epoch 133: 0.29460909343454145\n",
            "Epoch 134: 0.294135618230552\n",
            "Epoch 135: 0.2942711427850137\n",
            "Epoch 137: 0.29500074784539687\n",
            "Epoch 138: 0.29463737862518\n",
            "Epoch 139: 0.29519875268368967\n",
            "Epoch 140: 0.2942381252689752\n",
            "Epoch 141: 0.29491855291049196\n",
            "Epoch 142: 0.2955367392471578\n",
            "Epoch 143: 0.2943017009423474\n",
            "Epoch 144: 0.2942378340704122\n",
            "Epoch 145: 0.29451287563897943\n",
            "Epoch 146: 0.29532580471847897\n",
            "Epoch 147: 0.29441920762477664\n",
            "Epoch 148: 0.29501675980449027\n",
            "Epoch 149: 0.2946246967767281\n",
            "Epoch 150: 0.29487229239905316\n",
            "Epoch 151: 0.2953396925945688\n",
            "Epoch 152: 0.29422165310602916\n",
            "Epoch 153: 0.2952076998447862\n",
            "Epoch 154: 0.2952514979011983\n",
            "Epoch 155: 0.2944829213083289\n",
            "Epoch 156: 0.2948951203797909\n",
            "Epoch 157: 0.29458045143775297\n",
            "Epoch 158: 0.29448928432852645\n",
            "Epoch 159: 0.29490263667737276\n",
            "Epoch 160: 0.2948539605164336\n",
            "Epoch 161: 0.29470967875784376\n",
            "Epoch 162: 0.2937748690487275\n",
            "Epoch 163: 0.2943746783017873\n",
            "Epoch 164: 0.29433788812771877\n",
            "Epoch 165: 0.29467686208170785\n",
            "Epoch 166: 0.2945583325995147\n",
            "Epoch 167: 0.2944770641721882\n",
            "Epoch 168: 0.2959760935390624\n",
            "Epoch 169: 0.29470075439952653\n",
            "Epoch 170: 0.29414241937138136\n",
            "Epoch 171: 0.2941867812419189\n",
            "Epoch 172: 0.29569509336582417\n",
            "Epoch 174: 0.2937832889565255\n",
            "Epoch 175: 0.294491573970149\n",
            "Epoch 176: 0.2950104965548925\n",
            "Epoch 177: 0.2942398218113944\n",
            "Epoch 178: 0.2947375624760921\n",
            "Epoch 180: 0.29417955057406653\n",
            "Epoch 181: 0.29376448331799426\n",
            "Epoch 182: 0.2952186278852443\n",
            "Epoch 183: 0.29536103399775737\n",
            "Epoch 184: 0.29457372364213474\n",
            "Epoch 185: 0.29335686724488713\n",
            "Epoch 186: 0.29407775784595186\n",
            "Epoch 187: 0.2947471808621459\n",
            "Epoch 188: 0.2942433794544048\n",
            "Epoch 189: 0.2938078371898017\n",
            "Epoch 190: 0.29436514898691946\n",
            "Epoch 191: 0.2944026696712534\n",
            "Epoch 192: 0.2936856336280634\n",
            "Epoch 193: 0.29367105863944304\n",
            "Epoch 194: 0.29466764595568806\n",
            "Epoch 195: 0.29484079522217504\n",
            "Epoch 196: 0.29456804536423287\n",
            "Epoch 197: 0.29439772202336717\n",
            "Epoch 198: 0.2941657978851918\n",
            "Epoch 200: 0.2937293035236904\n",
            "Epoch 201: 0.2934537433560677\n",
            "Epoch 202: 0.2946656863855617\n",
            "Epoch 203: 0.29446316091388247\n",
            "Epoch 204: 0.29393256277017377\n",
            "Epoch 205: 0.2940735648056872\n",
            "Epoch 206: 0.2948764867150836\n",
            "Epoch 207: 0.2936574343667296\n",
            "Epoch 208: 0.29367481344893687\n",
            "Epoch 209: 0.29464707614099195\n",
            "Epoch 210: 0.29413050143993547\n",
            "Epoch 211: 0.29478557544431516\n",
            "Epoch 213: 0.293185586158265\n",
            "Epoch 214: 0.2942753203508492\n",
            "Epoch 215: 0.2938253975548672\n",
            "Epoch 216: 0.2938874653517538\n",
            "Epoch 217: 0.29400387050795956\n",
            "Epoch 218: 0.29448992947796726\n",
            "Epoch 219: 0.2940113208960703\n",
            "Epoch 220: 0.29329684641303816\n",
            "Epoch 221: 0.2941042068247047\n",
            "Epoch 222: 0.2946300705079722\n",
            "Epoch 223: 0.2941547294163223\n",
            "Epoch 224: 0.2943377615625959\n",
            "Epoch 225: 0.29417028087650665\n",
            "Epoch 227: 0.2942166011203079\n",
            "Epoch 228: 0.2933562957967793\n",
            "Epoch 230: 0.29405651333721766\n",
            "Epoch 231: 0.29442800133804564\n",
            "Epoch 232: 0.2944076425430151\n",
            "Epoch 233: 0.29497381094078534\n",
            "Epoch 234: 0.2930272488999768\n",
            "Epoch 236: 0.29395022974305407\n",
            "Epoch 237: 0.2939844073787999\n",
            "Epoch 239: 0.2945454576338916\n",
            "Epoch 240: 0.29379950674345395\n",
            "Epoch 241: 0.2939677942746477\n",
            "Epoch 242: 0.29403776318146246\n",
            "Epoch 243: 0.29395005231818877\n",
            "Epoch 245: 0.29364459601921167\n",
            "Epoch 246: 0.2949683676950681\n",
            "Epoch 247: 0.29313840404356617\n",
            "Epoch 248: 0.2946953440337234\n",
            "Epoch 249: 0.2945005932139719\n",
            "Epoch 250: 0.2936825131952705\n",
            "Epoch 251: 0.29343227593074944\n",
            "Epoch 252: 0.29349725736363386\n",
            "Epoch 253: 0.2930288888877442\n",
            "Epoch 254: 0.2949287716899142\n",
            "Epoch 255: 0.29449587490628576\n",
            "Epoch 256: 0.2956168846443964\n",
            "Epoch 257: 0.29446168072852064\n",
            "Epoch 258: 0.2946292360055486\n",
            "Epoch 259: 0.2931837818647557\n",
            "Epoch 260: 0.2937899334122021\n",
            "Epoch 261: 0.2942975364092308\n",
            "Epoch 262: 0.29408605507570956\n",
            "Epoch 263: 0.29456244285804717\n",
            "Epoch 264: 0.29353004093219653\n",
            "Epoch 265: 0.2933844986073962\n",
            "Epoch 266: 0.2933814130650205\n",
            "Epoch 267: 0.2939353256810285\n",
            "Epoch 268: 0.2939266566442792\n",
            "Epoch 269: 0.29352948251259314\n",
            "Epoch 270: 0.2940603645725529\n",
            "Epoch 271: 0.2939189759682798\n",
            "Epoch 272: 0.29394652914511504\n",
            "Epoch 273: 0.2939661975424154\n",
            "Epoch 274: 0.2938609081258134\n",
            "Epoch 275: 0.293511993288261\n",
            "Epoch 276: 0.29409165399007353\n",
            "Epoch 277: 0.2940108647552851\n",
            "Epoch 278: 0.2949913776681286\n",
            "Epoch 279: 0.29332226087974933\n",
            "Epoch 280: 0.2941296655201384\n",
            "Epoch 281: 0.29462357144177354\n",
            "Epoch 282: 0.29337576250205566\n",
            "Epoch 283: 0.29382923914103004\n",
            "Epoch 284: 0.2938286939684941\n",
            "Epoch 285: 0.29378160245817636\n",
            "Epoch 286: 0.2943316610591389\n",
            "Epoch 287: 0.29483080082988683\n",
            "Epoch 288: 0.2941672795593714\n",
            "Epoch 289: 0.2941962276960837\n",
            "Epoch 290: 0.29381850032363693\n",
            "Epoch 291: 0.29456374548185965\n",
            "Epoch 292: 0.29373636772096295\n",
            "Epoch 293: 0.29400610057589976\n",
            "Epoch 294: 0.2959542174687943\n",
            "Epoch 295: 0.2937565954969468\n",
            "Epoch 296: 0.2943884085782394\n",
            "Epoch 297: 0.2944112487715201\n",
            "Epoch 298: 0.29407352680202775\n",
            "Epoch 299: 0.2944239904251469\n",
            "Epoch 300: 0.2941057141421766\n",
            "Epoch 302: 0.29335654977385356\n",
            "Epoch 303: 0.2946082841624861\n",
            "Epoch 305: 0.2938051237979033\n",
            "Epoch 306: 0.29307514801766826\n",
            "Epoch 308: 0.2931404373642513\n",
            "Epoch 309: 0.29294745049933896\n",
            "Epoch 310: 0.2928653280180983\n",
            "Epoch 311: 0.2934687226516537\n",
            "Epoch 312: 0.2944810237607814\n",
            "Epoch 313: 0.29300440253442656\n",
            "Epoch 314: 0.2932728651267728\n",
            "Epoch 315: 0.2934146158600303\n",
            "Epoch 316: 0.294168254674204\n",
            "Epoch 317: 0.2937564940444927\n",
            "Epoch 318: 0.29340372220225325\n",
            "Epoch 319: 0.29412305407076966\n",
            "Epoch 320: 0.29368028067016205\n",
            "Epoch 321: 0.2934069725667231\n",
            "Epoch 322: 0.29339879579995787\n",
            "Epoch 323: 0.29363713632627436\n",
            "Epoch 324: 0.29410468815381263\n",
            "Epoch 325: 0.29364479900140505\n",
            "Epoch 326: 0.2937334507480676\n",
            "Epoch 327: 0.29310023853909856\n",
            "Epoch 328: 0.29322329589269863\n",
            "Epoch 329: 0.29323560641023033\n",
            "Epoch 330: 0.2935461838760236\n",
            "Epoch 331: 0.29389739041965934\n",
            "Epoch 332: 0.2944617313332712\n",
            "Epoch 333: 0.29349535344343286\n",
            "Epoch 334: 0.29428475130414017\n",
            "Epoch 335: 0.2939093685035402\n",
            "Epoch 336: 0.29506644438192087\n",
            "Epoch 337: 0.2935756120058009\n",
            "Epoch 338: 0.29400934428089004\n",
            "Epoch 339: 0.29327283972182816\n",
            "Epoch 340: 0.2938155714871374\n",
            "Epoch 341: 0.29367170558639394\n",
            "Epoch 342: 0.2939449703176541\n",
            "Epoch 343: 0.29373352684338067\n",
            "Epoch 345: 0.2937376486433856\n",
            "Epoch 346: 0.2938074187711898\n",
            "Epoch 347: 0.29378721985494605\n",
            "Epoch 348: 0.2938510705680422\n",
            "Epoch 349: 0.2927768205748801\n",
            "Epoch 350: 0.29329017808481056\n",
            "Epoch 351: 0.2942728517963873\n",
            "Epoch 352: 0.2934734955547054\n",
            "Epoch 353: 0.29370927680573816\n",
            "Epoch 354: 0.2936376945411493\n",
            "Epoch 355: 0.293994075747896\n",
            "Epoch 356: 0.2937578382866666\n",
            "Epoch 357: 0.29339313287450874\n",
            "Epoch 358: 0.2935530875055158\n",
            "Epoch 359: 0.2942414043981162\n",
            "Epoch 360: 0.2935290890799619\n",
            "Epoch 361: 0.29395347406456535\n",
            "Epoch 362: 0.29411489721197814\n",
            "Epoch 363: 0.293200655387319\n",
            "Epoch 364: 0.29356424210786586\n",
            "Epoch 365: 0.2934573486123297\n",
            "Epoch 366: 0.2944760394776504\n",
            "Epoch 367: 0.29414100089688744\n",
            "Epoch 368: 0.2934253313712246\n",
            "Epoch 369: 0.2935681886290327\n",
            "Epoch 370: 0.29446400853804705\n",
            "Epoch 371: 0.2931771872045826\n",
            "Epoch 372: 0.293349400235186\n",
            "Epoch 373: 0.2935422497498294\n",
            "Epoch 375: 0.29265824711856997\n",
            "Epoch 376: 0.29319633545143503\n",
            "Epoch 377: 0.2936388109677156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8185cd7096cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Epoch {i}: {sqrt(loss.item())}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;31m# PATH = 'model.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}