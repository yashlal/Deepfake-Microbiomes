{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArchitectureGPU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM8vidD4jVVABll4eY5R37w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yashlal/Deepfake-Microbiomes/blob/main/ArchitectureGPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "9A62bgwH6azv",
        "outputId": "1e63d851-ecdd-401d-dc74-a927a8872e91"
      },
      "source": [
        "from newsolver import predict_community_fullnp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random as rd\n",
        "from numba import njit\n",
        "from numba.typed import List\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "import torch.optim as optim\n",
        "import time\n",
        "from math import sqrt\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "from scipy.stats import wasserstein_distance as WD\n",
        "\n",
        "data = pd.read_excel('RealData.xlsx', index_col=0)\n",
        "specs = data.columns.tolist()\n",
        "trimmed_specs = []\n",
        "typed_trimmed_specs = List()\n",
        "\n",
        "for i in range(len(specs)):\n",
        "    if data.iloc[:,i].astype(bool).sum() >= 85:\n",
        "        trimmed_specs.append(specs[i])\n",
        "        typed_trimmed_specs.append(specs[i])\n",
        "\n",
        "@njit()\n",
        "def get_LT(full_ar):\n",
        "    ar = []\n",
        "    for i in range(len(full_ar)):\n",
        "        for j in range(i):\n",
        "            ar.append(full_ar[i][j])\n",
        "    return ar\n",
        "\n",
        "@njit()\n",
        "def generate_matrix(comm):\n",
        "    dim = len(comm)\n",
        "    ar = np.zeros((dim,dim))\n",
        "\n",
        "    for i in range(dim):\n",
        "        for j in range(i+1):\n",
        "            if i == j:\n",
        "                ar[i][j] = 0\n",
        "            else:\n",
        "                r = rd.random()\n",
        "                ar[i][j] = r\n",
        "                ar[j][i] = 1-r\n",
        "\n",
        "    return ar\n",
        "\n",
        "def generate_train_set(n):\n",
        "    train_x = []\n",
        "    full_m = pd.DataFrame(generate_matrix(trimmed_specs), index=trimmed_specs, columns=trimmed_specs)\n",
        "    train_y = get_LT(full_m.to_numpy())\n",
        "\n",
        "    pbar2=tqdm(range(n))\n",
        "    pbar2.set_description('Generating Train Data')\n",
        "    for epoch in pbar2:\n",
        "\n",
        "        npcm = np.zeros(len(trimmed_specs))\n",
        "        size = rd.randint(25, 235)\n",
        "        subset = rd.sample(trimmed_specs, size)\n",
        "        subset_lam = (full_m.loc[subset, subset]).to_numpy()\n",
        "        cm = predict_community_fullnp(subset_lam, subset, verb=False)\n",
        "\n",
        "        for i in subset:\n",
        "            npcm[trimmed_specs.index(i)] = 0\n",
        "        for i in range(len(cm)):\n",
        "            npcm[trimmed_specs.index(subset[i])] = cm[i]\n",
        "        train_x.append(npcm)\n",
        "\n",
        "    return train_x, train_y\n",
        "\n",
        "# select CUDA if available\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if str(device) == 'cuda:0':\n",
        "    print('CUDA device selected!')\n",
        "elif str(device) == 'cpu':\n",
        "\tprint('CUDA device not available. CPU selected')\n",
        "\n",
        "\n",
        "class MyNet(nn.Module):\n",
        "    def __init__(self, hyperparam):\n",
        "        super(MyNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(462, hyperparam)\n",
        "        self.fc2 = nn.Linear(hyperparam, 231*461)\n",
        "    def forward(self,x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "def train_net(model, train_size):\n",
        "    pbar2=tqdm(range(train_size))\n",
        "    pbar2.set_description('Training Neural Net')\n",
        "    train_x, train_y = generate_train_set(n=train_size)\n",
        "\n",
        "    for i in pbar2:\n",
        "        optimizer.zero_grad()\n",
        "        x, y = train_x[i], train_y\n",
        "        input = torch.from_numpy(x).float().to(device)\n",
        "        true_y = torch.FloatTensor(y).to(device)\n",
        "        output = model(input).to(device)\n",
        "        loss = criterion(output, true_y).to(device)\n",
        "        s = sqrt(loss.item()/(231*461))\n",
        "        print(f'Epoch {i}: Loss {s}')\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "if __name__=='__main__':\n",
        "\n",
        "    train_size, test_size, param = 5000, 25, 500\n",
        "\n",
        "    net = MyNet(param).to(device)\n",
        "\n",
        "    #Multi GPU Support\n",
        "    if torch.cuda.device_count() > 1:\n",
        "          print(f'Using {torch.cuda.device_count()} GPUs')\n",
        "          net = nn.DataParallel(net)\n",
        "    elif torch.cuda.device_count() == 1:\n",
        "        print(f'Using {torch.cuda.device_count()} GPU')\n",
        "\n",
        "    criterion = nn.MSELoss(reduction='sum')\n",
        "    optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
        "    train_net(net, train_size=train_size)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e47606f1a6f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnewsolver\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpredict_community_fullnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnjit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'newsolver'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    }
  ]
}